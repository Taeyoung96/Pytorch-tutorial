{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Network\n",
    "\n",
    "- Mnist data\n",
    "- 3 convolutional layers\n",
    "- 2 fully connected layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setting\n",
    "\n",
    "### 1) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1   #시간이 너무 오래 걸린다...\n",
    "batch_size = 16\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist data는 이미 torch에 있다.  target_transform -> target을 바꾸어 주지 않겠다.\n",
    "mnist_train = dset.MNIST(\"./\",train = True, transform = transforms.ToTensor(), target_transform = None, download = True)\n",
    "mnist_test  = dset.MNIST(\"./\",train = False, transform = transforms.ToTensor(), target_transform = None, download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the datasets download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n",
      "torch.Size([1, 28, 28]) 5\n",
      "torch.Size([1, 28, 28]) 7\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train.__len__())\n",
    "print(mnist_test.__len__())\n",
    "\n",
    "# dataset이 잘 받아졌나, 어떤 모양인지 확인하는 작업\n",
    "img1, label1 = mnist_train.__getitem__(0)\n",
    "img2, label2 = mnist_test.__getitem__(0)\n",
    "\n",
    "print(img1.size(), label1)\n",
    "print(img2.size(), label2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Data Loader (input pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_train, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(1,16,5), \n",
    "                        #mnist는 (28,28,1)이기 때문에 앞에 채널 수와 같은 1을 써줌.\n",
    "                        #원하는 output의 channel이 16이므로 16, kernal_size를 5로 해준다.\n",
    "                        # ouput -> batch * (16 * 24 * 24)\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(16,32,5),\n",
    "                        #conv1을 통과한 채널의 수가 16이므로 ,input은 16,\n",
    "                        #원하는 output의 채널의 수가 32이므로 32, kernal_size는 5로 해준다.\n",
    "                        # output -> batch * (32 * 20 * 20)\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2,2)\n",
    "                        # output -> batch * (32 * 10 * 10)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "                        nn.Conv2d(32,64,5),\n",
    "                        # output -> batch * (64 * 6 * 6)\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(64,128,5),\n",
    "                        # output -> batch * (128 * 2 * 2)\n",
    "                        nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(2*2*128,10)  \n",
    "        #(채널수 * width * height) 를 input으로 넣고, output을 10으로 맞춰준다.\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "cnn = CNN().cuda()\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7097, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        image = Variable(image).cuda()\n",
    "        label = Variable(label).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        result = cnn.forward(image)  #cnn(image)해도 똑같이 forward가 진행된다.\n",
    "        loss = loss_func(result,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j % 100 == 0:\n",
    "            print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test image: 98.000000 %\n"
     ]
    }
   ],
   "source": [
    "cnn.eval()  #dropout하고 batchnormalization 이 부분이 정지 되는 부분 -> 모델을 고정시킨다고 생각하자.\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for image,label in  test_loader:\n",
    "    image = Variable(image).cuda()\n",
    "    result = cnn(image).cuda()\n",
    "    \n",
    "    _, predicted = torch.max(result.data, 1)\n",
    "    total += label.size(0)\n",
    "    correct += (predicted == label.cuda()).sum()\n",
    "\n",
    "print(\"Test Accuracy of the model on the 10000 test image: %f %%\" % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
