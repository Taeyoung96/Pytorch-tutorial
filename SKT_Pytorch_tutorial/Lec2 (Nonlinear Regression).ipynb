{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "- Non-Linear Data\n",
    "- Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "num_data = 100\n",
    "num_epoch = 1000\n",
    "\n",
    "noise = init.normal_(torch.FloatTensor(num_data,1),std = 1)\n",
    "x = init.uniform_(torch.Tensor(num_data,1),-15,15)\n",
    "y = -x**3 - 8*(x**2) + 3\n",
    "\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Linear(1,6),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(6,10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(10,6),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(6,1),\n",
    "    )\n",
    "\n",
    "output = model(Variable(x))\n",
    "\n",
    "loss_func = nn.L1Loss() #Binary Cross Entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  1076.1087646484375\n",
      "loss :  1076.0347900390625\n",
      "loss :  1075.9527587890625\n",
      "loss :  1075.858642578125\n",
      "loss :  1075.7432861328125\n",
      "loss :  1075.60205078125\n",
      "loss :  1075.4332275390625\n",
      "loss :  1075.2236328125\n",
      "loss :  1074.968017578125\n",
      "loss :  1074.656005859375\n",
      "loss :  1074.2752685546875\n",
      "loss :  1073.8135986328125\n",
      "loss :  1073.2587890625\n",
      "loss :  1072.5960693359375\n",
      "loss :  1071.8052978515625\n",
      "loss :  1070.867431640625\n",
      "loss :  1069.7586669921875\n",
      "loss :  1068.45849609375\n",
      "loss :  1066.9412841796875\n",
      "loss :  1065.1800537109375\n",
      "loss :  1063.146240234375\n",
      "loss :  1060.83056640625\n",
      "loss :  1058.1875\n",
      "loss :  1055.198486328125\n",
      "loss :  1051.8421630859375\n",
      "loss :  1048.030029296875\n",
      "loss :  1043.7088623046875\n",
      "loss :  1038.9144287109375\n",
      "loss :  1033.5186767578125\n",
      "loss :  1027.5047607421875\n",
      "loss :  1020.931640625\n",
      "loss :  1013.7215576171875\n",
      "loss :  1005.7371826171875\n",
      "loss :  996.9014282226562\n",
      "loss :  987.1488037109375\n",
      "loss :  976.7388305664062\n",
      "loss :  965.6057739257812\n",
      "loss :  953.6766357421875\n",
      "loss :  941.00146484375\n",
      "loss :  927.9920043945312\n",
      "loss :  914.771728515625\n",
      "loss :  901.1490478515625\n",
      "loss :  886.6369018554688\n",
      "loss :  871.4888305664062\n",
      "loss :  855.4823608398438\n",
      "loss :  839.52392578125\n",
      "loss :  823.8117065429688\n",
      "loss :  807.7645874023438\n",
      "loss :  791.8111572265625\n",
      "loss :  775.6339721679688\n",
      "loss :  758.8421630859375\n",
      "loss :  741.29736328125\n",
      "loss :  725.090087890625\n",
      "loss :  708.9879760742188\n",
      "loss :  692.130615234375\n",
      "loss :  675.8992309570312\n",
      "loss :  660.069580078125\n",
      "loss :  643.5675048828125\n",
      "loss :  626.2909545898438\n",
      "loss :  609.8140258789062\n",
      "loss :  594.012939453125\n",
      "loss :  581.0215454101562\n",
      "loss :  569.7207641601562\n",
      "loss :  560.1532592773438\n",
      "loss :  551.7479858398438\n",
      "loss :  544.0011596679688\n",
      "loss :  536.8690185546875\n",
      "loss :  529.6289672851562\n",
      "loss :  522.1448974609375\n",
      "loss :  514.5369873046875\n",
      "loss :  506.68438720703125\n",
      "loss :  499.2974853515625\n",
      "loss :  492.787109375\n",
      "loss :  487.165283203125\n",
      "loss :  482.0959777832031\n",
      "loss :  477.03497314453125\n",
      "loss :  471.9790954589844\n",
      "loss :  467.7412414550781\n",
      "loss :  463.8955078125\n",
      "loss :  460.09100341796875\n",
      "loss :  456.29449462890625\n",
      "loss :  452.587646484375\n",
      "loss :  448.9227294921875\n",
      "loss :  445.326416015625\n",
      "loss :  442.4786682128906\n",
      "loss :  439.7284851074219\n",
      "loss :  437.2837829589844\n",
      "loss :  435.1133728027344\n",
      "loss :  433.06036376953125\n",
      "loss :  431.0749206542969\n",
      "loss :  429.1046142578125\n",
      "loss :  427.0819396972656\n",
      "loss :  425.104248046875\n",
      "loss :  423.0972900390625\n",
      "loss :  421.17645263671875\n",
      "loss :  419.3575744628906\n",
      "loss :  417.5777587890625\n",
      "loss :  415.8040771484375\n",
      "loss :  414.02130126953125\n",
      "loss :  412.2161865234375\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "loss_arr = []\n",
    "label = Variable(y_noise)\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    output = model(Variable(x))\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = loss_func(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(\"loss : \",loss.data.item())\n",
    "    \n",
    "    loss_arr.append(loss.data.numpy())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3887],\n",
      "        [-2.1205],\n",
      "        [ 1.6576],\n",
      "        [-0.5619],\n",
      "        [-1.5243],\n",
      "        [ 2.0748]]) tensor([-2.7906,  0.5851,  0.5841, -2.8964,  1.3696, -0.7322])\n"
     ]
    }
   ],
   "source": [
    "### 5. Check Trained Parameters\n",
    "\n",
    "param_list = list(model.parameters())\n",
    "print(param_list[0].data, param_list[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
