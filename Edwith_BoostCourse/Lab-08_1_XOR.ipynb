{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR with Linear Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "# for reproducibility\n",
    "torch.manual_seed(815)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(815)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU로 Train을 돌릴 것이기 때문에 .to(device)를 붙여준다.\n",
    "\n",
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)  \n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(2,1,bias = True)  # Input : 2, Output : 1\n",
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = nn.Sequential(linear, sigmoid).to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss().to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7062350511550903\n",
      "1000 0.6931471824645996\n",
      "2000 0.6931471824645996\n",
      "3000 0.6931471824645996\n",
      "4000 0.6931471824645996\n",
      "5000 0.6931471824645996\n",
      "6000 0.6931471824645996\n",
      "7000 0.6931471824645996\n",
      "8000 0.6931471824645996\n",
      "9000 0.6931471824645996\n",
      "10000 0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    # 결과 예측 \n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # cost/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    \n",
    "   \n",
    "    optimizer.zero_grad()    # 기울기 값 초기화\n",
    "    cost.backward()          # 기울기 값 Update\n",
    "    optimizer.step()         # 기울기 값으로 Weight값 Update\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis: \n",
      " [[0.49999714]\n",
      " [0.49999547]\n",
      " [0.49999547]\n",
      " [0.4999938 ]]\n",
      "Correct: \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Accuracy: \n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "\n",
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('Hypothesis: \\n', hypothesis.detach().cpu().numpy())    # hypothesis.cpu().numpy()랑 같다!\n",
    "    print('Correct: \\n', predicted.detach().cpu().numpy())\n",
    "    print('Accuracy: \\n', accuracy.item())\n",
    "    \n",
    "# Tensor를 Numpy로 변경해주려면 cpu()로 변경을 해주고 변환을 진행해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아무리 학습을 시켜도 정확도가 0.5가 나온다! \n",
    "### >> Layer를 늘려서 Train을 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Layer를 2개로 늘린 것 이외에는 모든 것이 동일!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)  \n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear1 = nn.Linear(2, 2, bias=True)\n",
    "linear2 = nn.Linear(2, 1, bias=True)\n",
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = nn.Sequential(linear1, sigmoid, linear2, sigmoid).to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss().to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.695436954498291\n",
      "1000 0.0024990083184093237\n",
      "2000 0.0010658728424459696\n",
      "3000 0.0006756555521860719\n",
      "4000 0.0004940968938171864\n",
      "5000 0.0003892949316650629\n",
      "6000 0.0003210976137779653\n",
      "7000 0.0002731611020863056\n",
      "8000 0.00023767226957716048\n",
      "9000 0.0002103075385093689\n",
      "10000 0.00018859218107536435\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    \n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # cost/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis: \n",
      " [[1.6553845e-04]\n",
      " [9.9979180e-01]\n",
      " [9.9979180e-01]\n",
      " [1.7230240e-04]]\n",
      "Correct: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Accuracy: \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "\n",
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('Hypothesis: \\n', hypothesis.detach().cpu().numpy())    # hypothesis.cpu().numpy()랑 같다!\n",
    "    print('Correct: \\n', predicted.detach().cpu().numpy())\n",
    "    print('Accuracy: \\n', accuracy.item())\n",
    "    \n",
    "# Tensor를 Numpy로 변경해주려면 cpu()로 변경을 해주고 변환을 진행해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model에 더 많은 Layer를 늘려서 Train을 해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer 4개로 Model을 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear1 = nn.Linear(2, 10, bias=True)\n",
    "linear2 = nn.Linear(10, 10, bias=True)\n",
    "linear3 = nn.Linear(10, 10, bias=True)\n",
    "linear4 = nn.Linear(10, 1, bias=True)\n",
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid, linear3, sigmoid, linear4, sigmoid).to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss().to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)   # learning rate를 조절해보며 Train해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.4809963835868984e-05\n",
      "1000 3.402016227482818e-05\n",
      "2000 3.327506783534773e-05\n",
      "3000 3.252997703384608e-05\n",
      "4000 3.182958971592598e-05\n",
      "5000 3.1159008358372375e-05\n",
      "6000 3.0533134122379124e-05\n",
      "7000 2.992216104757972e-05\n",
      "8000 2.9340990295168012e-05\n",
      "9000 2.8759821361745708e-05\n",
      "10000 2.8208458388689905e-05\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # cost/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis: \n",
      " [[6.4789215e-06]\n",
      " [9.9995506e-01]\n",
      " [9.9995315e-01]\n",
      " [1.4523312e-05]]\n",
      "Correct: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Accuracy: \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "\n",
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('Hypothesis: \\n', hypothesis.detach().cpu().numpy())    # hypothesis.cpu().numpy()랑 같다!\n",
    "    print('Correct: \\n', predicted.detach().cpu().numpy())\n",
    "    print('Accuracy: \\n', accuracy.item())\n",
    "    \n",
    "# Tensor를 Numpy로 변경해주려면 cpu()로 변경을 해주고 변환을 진행해야 한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
